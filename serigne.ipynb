{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_10</th>\n",
       "      <th>col_14</th>\n",
       "      <th>col_23</th>\n",
       "      <th>col_34</th>\n",
       "      <th>col_35</th>\n",
       "      <th>col_37</th>\n",
       "      <th>col_39</th>\n",
       "      <th>col_40</th>\n",
       "      <th>col_41</th>\n",
       "      <th>col_43</th>\n",
       "      <th>col_44</th>\n",
       "      <th>col_49</th>\n",
       "      <th>GoodCustomer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.203197</td>\n",
       "      <td>-0.740479</td>\n",
       "      <td>2.087583</td>\n",
       "      <td>2.523667</td>\n",
       "      <td>-1.497972</td>\n",
       "      <td>1.706032</td>\n",
       "      <td>-1.533774</td>\n",
       "      <td>0.590063</td>\n",
       "      <td>0.515355</td>\n",
       "      <td>-1.102233</td>\n",
       "      <td>0.793082</td>\n",
       "      <td>-3.123545</td>\n",
       "      <td>-1.138130</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.521785</td>\n",
       "      <td>0.716828</td>\n",
       "      <td>1.866058</td>\n",
       "      <td>-0.586905</td>\n",
       "      <td>-1.162075</td>\n",
       "      <td>0.232352</td>\n",
       "      <td>-1.487904</td>\n",
       "      <td>1.313987</td>\n",
       "      <td>-0.407439</td>\n",
       "      <td>2.158395</td>\n",
       "      <td>-0.003680</td>\n",
       "      <td>0.234569</td>\n",
       "      <td>0.163475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.443184</td>\n",
       "      <td>-1.971204</td>\n",
       "      <td>1.580057</td>\n",
       "      <td>-0.042849</td>\n",
       "      <td>1.504893</td>\n",
       "      <td>0.470849</td>\n",
       "      <td>-1.458726</td>\n",
       "      <td>0.488531</td>\n",
       "      <td>-0.223588</td>\n",
       "      <td>-0.652124</td>\n",
       "      <td>0.480149</td>\n",
       "      <td>-1.068155</td>\n",
       "      <td>1.004818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.187760</td>\n",
       "      <td>0.923105</td>\n",
       "      <td>1.707140</td>\n",
       "      <td>-1.466182</td>\n",
       "      <td>-0.204355</td>\n",
       "      <td>-2.159234</td>\n",
       "      <td>0.900358</td>\n",
       "      <td>-3.479476</td>\n",
       "      <td>-0.602378</td>\n",
       "      <td>-2.235828</td>\n",
       "      <td>-0.638585</td>\n",
       "      <td>-0.189545</td>\n",
       "      <td>-0.421030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.410303</td>\n",
       "      <td>2.005181</td>\n",
       "      <td>0.330991</td>\n",
       "      <td>-1.492493</td>\n",
       "      <td>1.847506</td>\n",
       "      <td>0.362453</td>\n",
       "      <td>0.183824</td>\n",
       "      <td>-0.709925</td>\n",
       "      <td>1.258906</td>\n",
       "      <td>-0.025172</td>\n",
       "      <td>-1.475451</td>\n",
       "      <td>-2.673422</td>\n",
       "      <td>-0.978382</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      col_3    col_10    col_14    col_23    col_34    col_35    col_37  \\\n",
       "0  2.203197 -0.740479  2.087583  2.523667 -1.497972  1.706032 -1.533774   \n",
       "1  1.521785  0.716828  1.866058 -0.586905 -1.162075  0.232352 -1.487904   \n",
       "2 -1.443184 -1.971204  1.580057 -0.042849  1.504893  0.470849 -1.458726   \n",
       "3  0.187760  0.923105  1.707140 -1.466182 -0.204355 -2.159234  0.900358   \n",
       "4 -1.410303  2.005181  0.330991 -1.492493  1.847506  0.362453  0.183824   \n",
       "\n",
       "     col_39    col_40    col_41    col_43    col_44    col_49  GoodCustomer  \n",
       "0  0.590063  0.515355 -1.102233  0.793082 -3.123545 -1.138130             1  \n",
       "1  1.313987 -0.407439  2.158395 -0.003680  0.234569  0.163475             0  \n",
       "2  0.488531 -0.223588 -0.652124  0.480149 -1.068155  1.004818             0  \n",
       "3 -3.479476 -0.602378 -2.235828 -0.638585 -0.189545 -0.421030             0  \n",
       "4 -0.709925  1.258906 -0.025172 -1.475451 -2.673422 -0.978382             0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('globaldata_.csv')  \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = data.drop(['GoodCustomer'] , axis=1)  \n",
    "y = data['GoodCustomer']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_t, y_train, y_t = train_test_split(X, y, test_size=0.3)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_t, y_t, test_size=0.33) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Entraînement du modèle : LogisticRegression ---\n",
      "Précision sur validation pour LogisticRegression : 0.7369\n",
      "Score F1 sur validation pour LogisticRegression : 0.7367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74      1003\n",
      "           1       0.74      0.72      0.73       977\n",
      "\n",
      "    accuracy                           0.74      1980\n",
      "   macro avg       0.74      0.74      0.74      1980\n",
      "weighted avg       0.74      0.74      0.74      1980\n",
      "\n",
      "Précision sur test pour LogisticRegression : 0.7400\n",
      "Score F1 sur test pour LogisticRegression : 0.7399\n",
      "\n",
      "--- Entraînement du modèle : RandomForest ---\n",
      "Précision sur validation pour RandomForest : 0.9207\n",
      "Score F1 sur validation pour RandomForest : 0.9207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92      1003\n",
      "           1       0.93      0.91      0.92       977\n",
      "\n",
      "    accuracy                           0.92      1980\n",
      "   macro avg       0.92      0.92      0.92      1980\n",
      "weighted avg       0.92      0.92      0.92      1980\n",
      "\n",
      "Précision sur test pour RandomForest : 0.9197\n",
      "Score F1 sur test pour RandomForest : 0.9197\n",
      "\n",
      "--- Entraînement du modèle : GradientBoosting ---\n",
      "Précision sur validation pour GradientBoosting : 0.8833\n",
      "Score F1 sur validation pour GradientBoosting : 0.8833\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89      1003\n",
      "           1       0.88      0.88      0.88       977\n",
      "\n",
      "    accuracy                           0.88      1980\n",
      "   macro avg       0.88      0.88      0.88      1980\n",
      "weighted avg       0.88      0.88      0.88      1980\n",
      "\n",
      "Précision sur test pour GradientBoosting : 0.8774\n",
      "Score F1 sur test pour GradientBoosting : 0.8773\n",
      "\n",
      "--- Entraînement du modèle : SVM ---\n",
      "Précision sur validation pour SVM : 0.8929\n",
      "Score F1 sur validation pour SVM : 0.8929\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90      1003\n",
      "           1       0.90      0.88      0.89       977\n",
      "\n",
      "    accuracy                           0.89      1980\n",
      "   macro avg       0.89      0.89      0.89      1980\n",
      "weighted avg       0.89      0.89      0.89      1980\n",
      "\n",
      "Précision sur test pour SVM : 0.8918\n",
      "Score F1 sur test pour SVM : 0.8918\n",
      "\n",
      "--- Entraînement du modèle : KNN ---\n",
      "Précision sur validation pour KNN : 0.8813\n",
      "Score F1 sur validation pour KNN : 0.8813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      1003\n",
      "           1       0.88      0.88      0.88       977\n",
      "\n",
      "    accuracy                           0.88      1980\n",
      "   macro avg       0.88      0.88      0.88      1980\n",
      "weighted avg       0.88      0.88      0.88      1980\n",
      "\n",
      "Précision sur test pour KNN : 0.8823\n",
      "Score F1 sur test pour KNN : 0.8823\n",
      "\n",
      "--- Résumé des performances ---\n",
      "LogisticRegression: Validation Précision = 0.7369, Test Précision = 0.7400\n",
      "RandomForest: Validation Précision = 0.9207, Test Précision = 0.9197\n",
      "GradientBoosting: Validation Précision = 0.8833, Test Précision = 0.8774\n",
      "SVM: Validation Précision = 0.8929, Test Précision = 0.8918\n",
      "KNN: Validation Précision = 0.8813, Test Précision = 0.8823\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Liste des modèles\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=200, random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=150, random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42 , n_estimators=200 , n_iter_no_change=5),\n",
    "    \"SVM\": SVC(probability=True, random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=3)\n",
    "}\n",
    "\n",
    "# Dictionnaire pour stocker les résultats\n",
    "results = {}\n",
    "\n",
    "# Boucle pour entraîner et évaluer chaque modèle\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n--- Entraînement du modèle : {name} ---\")\n",
    "    \n",
    "    # Entraînement sur l'ensemble d'entraînement\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Évaluation sur l'ensemble de validation\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    acc_val = accuracy_score(y_val, y_pred_val)\n",
    "    f1_val = f1_score(y_val, y_pred_val, average='weighted')\n",
    "    print(f\"Précision sur validation pour {name} : {acc_val:.4f}\")\n",
    "    print(f\"Score F1 sur validation pour {name} : {f1_val:.4f}\")\n",
    "    print(classification_report(y_val, y_pred_val))\n",
    "    \n",
    "    # Évaluation finale sur l'ensemble de test\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    acc_test = accuracy_score(y_test, y_pred_test)\n",
    "    f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "    print(f\"Précision sur test pour {name} : {acc_test:.4f}\")\n",
    "    print(f\"Score F1 sur test pour {name} : {f1_test:.4f}\")\n",
    "    \n",
    "    # Stocker les résultats\n",
    "    results[name] = {\n",
    "        \"Modèle\": model,\n",
    "        \"Validation Précision\": acc_val,\n",
    "        \"Validation F1-score\": f1_val,\n",
    "        \"Test Précision\": acc_test,\n",
    "        \"Test F1-score\": f1_test\n",
    "    }\n",
    "\n",
    "# Résumé des performances\n",
    "print(\"\\n--- Résumé des performances ---\")\n",
    "for name, info in results.items():\n",
    "    print(f\"{name}: Validation Précision = {info['Validation Précision']:.4f}, Test Précision = {info['Test Précision']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
